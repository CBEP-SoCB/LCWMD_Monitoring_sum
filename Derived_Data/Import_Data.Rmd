---
title: "LCWMD Data Import"
author: "Curtis C. Bohlen, Casco Bay Estuary Partnership"
date: "(Revised 7/21/2020)"
output:
  github_document:
    toc: true
    fig_width: 7
    fig_height: 5
---

<img
  src="https://www.cascobayestuary.org/wp-content/uploads/2014/04/logo_sm.jpg"
  style="position:absolute;top:10px;right:50px;" />

# Import Libraries
```{r load_libraries}
library(readxl)
library(tidyverse)
```

# Data Review
We begin by reviewing content of one of the Excel spreadsheets provided to us, 
for site S01.

We have some trouble reading in these files, because of their size. If we
mis-specify data types, it slows down loading. But if we get that right, we can
read these in fairly quickly.  It pays to specify data columns to speed the data
load process.
```{r load_test_data}
sibfldnm    <- 'Original_Data'
subfldnm    <- 'Data_Package_to_LCWMD'
subsubfldnm <- 'Data_by_Sites_Types'
parent      <- dirname(getwd())
sibling     <- file.path(parent,sibfldnm)

fn <- "S01 Merged Pressure and Sonde.xlsx"

fpath <- file.path(sibling, subfldnm, subsubfldnm, fn)

test.data <- read_excel(fpath, 
        sheet = "Consolidated 15 min",
        col_types = c("date", 
                "numeric", "numeric", "numeric", "numeric", 
                "numeric", "numeric", "numeric", "numeric", 
                "numeric", "numeric", "numeric", 
                "numeric"),
        skip = 2,
        na='NA#')
#View(test.data)
summary(test.data)
# rm(test.data)
```

The structure of the source Excel files is a bit confusing.  The consolidated
data in the first tab of each data sheet are derived from lookup formulas that
extract data from the source data, present in the "Sonde" and "Pressure" tabs.
The consolidated data sheet FIRST tries to pull matching data from the Sonde
data, and if that is not available, it then pulls data from the pressure
transducer.

That order of precedence is arguably incorrect for water depth, which is based
on pressure, and thus should be more accurate if derived from the pressure
transducers, not the sondes. However, it turns out that no pressure or depth
data was included in the sonde data (even though some sondes DO have pressure
sensors). We are correctly pulling depth data from the pressure transducers
only, despite the ambiguous formulas.

For some parameters, notably calculated chlorides, dissolved oxygen, and percent
saturation, each observation is split into two columns, the first being the
observation, and the second being labeled as "ND" in the original data.

Lets figure out what type of values those include.
```{r content_of_ND)}
fn <- "S01 Merged Pressure and Sonde.xlsx"
fpath <- file.path(sibling, subfldnm, subsubfldnm, fn)
test.data <- read_excel(fpath, 
        sheet = "Consolidated 15 min",
        col_types = c("skip", "skip", "text", "skip", 
                "skip", "text", "text", "skip", 
                "skip", "skip", "skip", "skip","skip"),
        skip = 2,
        na='NA#') %>%
    mutate_all(~factor(.))
test.data %>% summarise()
```
So, there is No data in those columns in the first spreadsheet.  We need to
check all available data, so I'll go through each spreadsheet in turn and see
whether these columns contain any non-missing values.
```{r all_ND, cache = TRUE}
results <- matrix(c(length(levels(test.data[,1])),
             length(levels(test.data[,2])),
             length(levels(test.data[,3]))), nrow=1)

othersites = c("S03", "S05", "S06B", "S07",  "S17")

for (site in othersites) {
    cat(site)
    cat("...")
    fn <- paste(site, "Merged Pressure and Sonde.xlsx")
    fpath <- file.path(sibling, subfldnm, subsubfldnm, fn)
    test.data <- read_excel(fpath, 
        sheet = "Consolidated 15 min",
        col_types = c("skip", "skip", "text", "skip", 
                "skip", "text", "text", "skip", 
                "skip", "skip", "skip", "skip","skip"),
        skip = 2,
        na='NA#') %>%
      mutate_all(~factor(.))
      current <- c(length(levels(test.data[,1])),
                   length(levels(test.data[,2])),
                   length(levels(test.data[,3])))
    results<- rbind(results, current)
}
rownames(results) <- c("S01", othersites)
results
```
So, there is no data in the the "ND" columns anywhere.  We can safely drop them.

```{r cleanup}
rm(test.data, results, current, site)
```

# Load Final Data
## First Site
Using column designations speeds up file import -- unless there are errors.  
Preparing and printing error messages drastically slows this code.

We load one data set first, to set up data format, before loading the other 
files.  This is not strictly necessary, but it's convenient to have a first 
dataframe to add others to using bind_rows.
```{r load_first}
fn <- "S01 Merged Pressure and Sonde.xlsx"
fpath <- file.path(sibling, subfldnm, subsubfldnm, fn)

the_data <- read_excel(fpath, 
        sheet = "Consolidated 15 min",
        col_types = c("date", 
                "numeric", "skip", "numeric", "numeric", 
                "skip", "skip", "numeric", "numeric", 
                "numeric", "numeric", "numeric", 
                "numeric"),
        skip = 2,
        na='NA#')
```

## Iterate over other sites
```{r load_others}
othersites = c("S03", "S05", "S06B", "S07",  "S17")
the_data <- the_data %>%
    mutate(Site = "S01" )
for (site in othersites) {
    cat(site)
    cat("...\n")
    fn <- paste(site, "Merged Pressure and Sonde.xlsx")
    fpath <- file.path(sibling, subfldnm, subsubfldnm, fn)
    
    tmp.data <- read_excel(fpath, 
            sheet = "Consolidated 15 min",
            col_types = c("date", 
                    "numeric", "skip", "numeric", "numeric", 
                    "skip", "skip", "numeric", "numeric", 
                    "numeric", "numeric", "numeric", 
                    "numeric"),
            skip = 2,
            na='NA#') %>%
        mutate(Site = site)
    the_data <- the_data %>% bind_rows(tmp.data)
}

```

## Rename and Reorder
It is worth noting that the data are NOT sorted by date and time, but apparently
by Month, day, and time.  That is, at least some of the time, Data with the same
calendar dates and times from different years are stored together.  I address
that in this next block of code.
```{r rename_and_reorder}
newnames <- c('DT', 'Chl', 'D', 'DO', 'PctSat', 'pH', 'Press', 'SpCond', 'T','Precip', 'Site')
names(the_data) <- newnames

the_data <- the_data %>%
    mutate(Site = factor(Site)) %>%
    arrange(Site, DT)

summary(the_data)

rm(tmp.data, site, newnames)
```

# Export the Data
```{r export_data}
write.csv(the_data, 'Sonde_Data.csv')
```


